{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper_functions import * \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_dirs = [\"Connecticut\"]\n",
    "ref_sets = [\"Connecticut\", \"USA\", \"North_America\", \"Global\"]\n",
    "dates = [\"2020-01-01_till_2022-01-01\", \"2020-06-01_till_2022-01-01\", \"2021-01-01_till_2022-01-01\", \"2021-06-01_till_2022-01-01\"]\n",
    "seeds = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "abundances = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write abundance predictions as json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ref_sts in  ref_sets:\n",
    "    output_results_to_json_3_dirs(first_dir = ref_sts, second_dirs=dates, third_dirs=seeds, threshold=\"0.1\", abundances= abundances, seq_name= \"AY.103_sequence\", prediction_level=\"VOC\", VOC= \"delta\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load abundance predictions & calculate absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "results_who = dict()\n",
    "\n",
    "for dir_name in ref_sets:\n",
    "    results[dir_name] = dict()\n",
    "    \n",
    "    with open(\"statistical_analysis/results_who_{}.json\".format(dir_name)) as json_file:\n",
    "        results_who[dir_name] = json.loads(json_file.read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate absolute errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_errors_who = calculate_absolute_errors_af(results_who, seeds, abundances, dates, ref_sets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_scatterplots_custom(abundances, dates, results, ref_sets, special_plot_name = None):\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(20, 20))\n",
    "    # fig.set_dpi(2000)\n",
    "\n",
    "    for ref_set, tuple in zip(ref_sets,[[0,0], [0,1], [1,0], [1,1]]):\n",
    "        i = tuple[0]\n",
    "        j = tuple[1]\n",
    "        \n",
    "        for date in dates:\n",
    "            # create a new figure\n",
    "            ax[i][j].scatter(abundances, [results[ref_set][date][\"1\"][str(abundance)] for abundance in abundances], label= date.replace(\"_\", \" \"), s = 170, alpha= 0.65)\n",
    "            ax[i][j].set_xscale('log')\n",
    "            ax[i][j].set_title(\"{}\".format(ref_set.replace(\"_\", \" \")), fontsize = 25, pad = 10)\n",
    "            \n",
    "        # plot x=y line black and dashed\n",
    "        ax[i][j].plot(abundances, abundances, color='black', linestyle='dashed', label = \"True abundance\")\n",
    "        # ax[i][j].legend(fontsize = 13)\n",
    "        ax[i][j].set_yticks([0, 10, 20, 30, 40, 50, 60, 70, 80 , 90, 100])\n",
    "    \n",
    "        ax[i][j].tick_params(axis='both', labelsize=20)\n",
    "    \n",
    "    # plot the same common legend outside of plot for all subplots\n",
    "    handles, labels = ax[0][0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='center right', bbox_to_anchor=(1.2, 0.5),fontsize = 20)\n",
    "\n",
    "    # plot commonn x annd y label\n",
    "    fig.text(0.5, 0.04, 'Simulated abundance', ha='center', fontsize = 25)\n",
    "    fig.text(0.04, 0.5, 'Predicted abundance', va='center', rotation='vertical', fontsize = 25)\n",
    "\n",
    "\n",
    "    # save figure as pdf with tight layout\n",
    "    plt.subplots_adjust(hspace=0.19)\n",
    "    if special_plot_name == None:\n",
    "        plt.savefig(\"figures/scatter_plot.pdf\", bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(\"figures/{}.pdf\".format(special_plot_name), bbox_inches='tight')\n",
    "\n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "plot_with_scatterplots_custom(abundances, dates, results_who, ref_sets, \"scatter_plot_who_custom\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [\"Connecticut\", \"USA\", \"North_America\", \"Global\"]\n",
    "start_dates = [\"2020-01-01_till_2022-01-01\", \"2020-06-01_till_2022-01-01\", \"2021-01-01_till_2022-01-01\", \"2021-06-01_till_2022-01-01\"]\n",
    "\n",
    "for ref_set in dirs:\n",
    "    for dates in start_dates:\n",
    "        path = \"../../../data/Timeframe_Experiments/HPC/reference_sets/{}/{}\".format(ref_set, dates)\n",
    "        selection_path = \"../../../data/Timeframe_Experiments/HPC/reference_sets/{}/{}/processed\".format(ref_set, dates)\n",
    "        output_dataset_info(\"AY.103\", path, selection_path)\n",
    "\n",
    "# merge csv per directory\n",
    "for dir in dirs:\n",
    "    merge_csv_from_subdirectory(\"../../../data/Timeframe_Experiments/HPC/reference_sets/{}\".format(dir, dates), \"Reference set\", True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_dirs = [\"Connecticut\"]\n",
    "ref_sets = [\"Connecticut\", \"USA\", \"North_America\", \"Global\"]\n",
    "dates = [\"2020-01-01_till_2022-01-01\", \"2020-06-01_till_2022-01-01\", \"2021-01-01_till_2022-01-01\", \"2021-06-01_till_2022-01-01\"]\n",
    "seeds = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "abundances = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  restructure absolute errors such that is absolute_errors[date][ref_set][seed][abundance]\n",
    "absolute_errors_resrtuctured = dict()\n",
    "\n",
    "for date in dates:\n",
    "    absolute_errors_resrtuctured[date] = dict()\n",
    "    for ref_set in ref_sets:\n",
    "        absolute_errors_resrtuctured[date][ref_set] = dict()\n",
    "        for seed in seeds:\n",
    "            seed = str(seed)\n",
    "            absolute_errors_resrtuctured[date][ref_set][seed] = dict()\n",
    "            for abundance in abundances:\n",
    "                abundance = str(abundance)\n",
    "                absolute_errors_resrtuctured[date][ref_set][seed][abundance] = absolute_errors_who[ref_set][date][seed][abundance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate t-test per date and reference set\n",
    "\n",
    "t_test_results = dict()\n",
    "\n",
    "recent_date = dates[len(dates)-1]\n",
    "\n",
    "for date in dates[:len(dates)-1]:\n",
    "    t_test_results[date] = dict()\n",
    "    for ref_set in ref_sets:\n",
    "        t_test_results[date][ref_set] = dict()\n",
    "        for abundance in abundances:\n",
    "            abundance = str(abundance)\n",
    "\n",
    "            # take abundance for each seed for date and ref_set\n",
    "            abundance_for_date_ref_set = [absolute_errors_resrtuctured[date][ref_set][str(seed)][abundance] for seed in seeds]\n",
    "\n",
    "            # take abundance for each seed for recent date and ref_set\n",
    "            abundance_for_recent_date_ref_set = [absolute_errors_resrtuctured[recent_date][ref_set][str(seed)][abundance] for seed in seeds]\n",
    "\n",
    "            # calculate t-test\n",
    "            t_test_results[date][ref_set][abundance] = stats.ttest_ind(abundance_for_recent_date_ref_set,abundance_for_date_ref_set, equal_var=False, alternative=\"less\")\n",
    "\n",
    "\n",
    "\n",
    "# save t-test results as dataframe and then as csv such that is dates vs abundances for each reference set\n",
    "\n",
    "for ref_set in ref_sets:\n",
    "    df = pd.DataFrame()\n",
    "    for date in dates[:len(dates)-1]:\n",
    "        df[date] = [t_test_results[date][ref_set][str(abundance)].pvalue for abundance in abundances]\n",
    "    df.index = abundances\n",
    "    df.to_csv(\"statistical_analysis/t-test_results_{}.csv\".format(ref_set))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap for p-values date  vs abundance for each reference set\n",
    "cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "\n",
    "# scale font size\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "for ref_set in ref_sets:\n",
    "\n",
    "    df = pd.read_csv(\"statistical_analysis/t-test_results_{}.csv\".format(ref_set), index_col=0)\n",
    "    # remove dashes from date column in place\n",
    "    df.columns = df.columns.str.replace(\"_\", \" \")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    # fig.set_dpi(2000)\n",
    "    sns.heatmap(df, cmap=cmap, linewidths=0.5, cbar_kws={\"shrink\": 0.5}, ax=ax, vmin=0, vmax = 0.1)\n",
    "\n",
    "    ax.set_title(\"{}\".format(ref_set.replace(\"_\", \" \")), fontsize = 25, pad = 10)\n",
    "    ax.set_xlabel(\"Date\", fontsize = 25)\n",
    "    ax.set_ylabel(\"Abundance\", fontsize = 25)\n",
    "    ax.tick_params(axis='both', labelsize=20)\n",
    "\n",
    "    # save figure as pdf with tight layout\n",
    "    plt.savefig(\"statistical_analysis/heatmap_{}.pdf\".format(ref_set), bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distribution over absolute errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_dirs = [\"Connecticut\"]\n",
    "ref_sets = [\"Connecticut\", \"USA\", \"North_America\", \"Global\"]\n",
    "dates = [\"2020-01-01_till_2022-01-01\", \"2020-06-01_till_2022-01-01\", \"2021-01-01_till_2022-01-01\", \"2021-06-01_till_2022-01-01\"]\n",
    "seeds = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "abundances = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "\n",
    "results = dict()\n",
    "results_who = dict()\n",
    "\n",
    "for dir_name in ref_sets:\n",
    "    results[dir_name] = dict()\n",
    "    \n",
    "    with open(\"statistical_analysis/results_who_{}.json\".format(dir_name)) as json_file:\n",
    "        results_who[dir_name] = json.loads(json_file.read())\n",
    "\n",
    "absolute_errors_who = calculate_absolute_errors_af(results_who, seeds, abundances, dates, ref_sets)\n",
    "\n",
    "#  restructure absolute errors such that is absolute_errors[date][ref_set][seed][abundance]\n",
    "absolute_errors_resrtuctured = dict()\n",
    "\n",
    "for date in dates:\n",
    "    absolute_errors_resrtuctured[date] = dict()\n",
    "    for ref_set in ref_sets:\n",
    "        absolute_errors_resrtuctured[date][ref_set] = dict()\n",
    "        for seed in seeds:\n",
    "            seed = str(seed)\n",
    "            absolute_errors_resrtuctured[date][ref_set][seed] = dict()\n",
    "            for abundance in abundances:\n",
    "                abundance = str(abundance)\n",
    "                absolute_errors_resrtuctured[date][ref_set][seed][abundance] = absolute_errors_who[ref_set][date][seed][abundance]\n",
    "\n",
    "# plot distribution of absolute errors for each date and reference set\n",
    "\n",
    "for date in dates:\n",
    "    for ref_set in ref_sets:\n",
    "        for ab in abundances:\n",
    "            fig, ax = plt.subplots(figsize=(20, 20))\n",
    "            ax.hist([absolute_errors_resrtuctured[date][ref_set][str(seed)][str(ab)] for seed in seeds], bins=100)\n",
    "            ax.set_title(\"{} {} {}\".format(ref_set, date, ab), fontsize = 25, pad = 10)\n",
    "            ax.set_xlabel(\"Absolute error\", fontsize = 25)\n",
    "            ax.set_ylabel(\"Frequency\", fontsize = 25)\n",
    "            ax.tick_params(axis='both', labelsize=20)\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
